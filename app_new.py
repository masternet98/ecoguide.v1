"""
EcoGuide.v1 - ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ê¸°ë°˜ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

ì´ë¯¸ì§€ ë¶„ì„ ì´í›„ í”„ë¡œì„¸ìŠ¤ë¥¼ ê¹”ë”í•˜ê²Œ ì¬êµ¬í˜„í•œ ë²„ì „ì…ë‹ˆë‹¤.
- ìœ„ì¹˜ ê¸°ëŠ¥: ë™ì‘ âœ“
- íê¸°ë¬¼ ë¶„ë¥˜ ê´€ë¦¬: ë™ì‘ âœ“
- ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ì „ì²˜ë¦¬: ë™ì‘ âœ“
- ì´ë¯¸ì§€ ë¶„ì„ ì´í›„ í”„ë¡œì„¸ìŠ¤: ìƒˆë¡œ êµ¬í˜„ âœ“

íë¦„:
1. ì´ë¯¸ì§€ ì—…ë¡œë“œ/ìº¡ì²˜ â†’ ì „ì²˜ë¦¬
2. OpenAI Vision APIë¡œ ë¶„ì„
3. JSON íŒŒì‹± ë° ì •ê·œí™”
4. íê¸°ë¬¼ ë¶„ë¥˜ ë§¤í•‘
5. ì‚¬ìš©ì í™•ì¸ ë° ìˆ˜ì •
6. ìµœì¢… ì œì¶œ
"""

import streamlit as st
import logging
from typing import Optional, Dict, Any
from datetime import datetime

from src.app.core.app_factory import get_application
from src.app.core.session_state import SessionStateManager
from src.app.core.error_handler import handle_errors, create_streamlit_error_ui, get_error_handler

logger = logging.getLogger(__name__)


class AnalysisState:
    """ì´ë¯¸ì§€ ë¶„ì„ ìƒíƒœë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self):
        """ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
        if 'analysis_step' not in st.session_state:
            st.session_state.analysis_step = 'image_input'  # image_input, analysis, confirmation, complete

        if 'current_image' not in st.session_state:
            st.session_state.current_image = None

        if 'analysis_result' not in st.session_state:
            st.session_state.analysis_result = None

        if 'normalized_result' not in st.session_state:
            st.session_state.normalized_result = None

        if 'label_saved' not in st.session_state:
            st.session_state.label_saved = False  # ë¼ë²¨ ì €ì¥ ì™„ë£Œ ì—¬ë¶€

    def set_step(self, step: str) -> None:
        """ë¶„ì„ ë‹¨ê³„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"""
        st.session_state.analysis_step = step

    def get_step(self) -> str:
        """í˜„ì¬ ë¶„ì„ ë‹¨ê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return st.session_state.analysis_step

    def set_image(self, image_bytes: bytes) -> None:
        """í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"""
        st.session_state.current_image = image_bytes

    def get_image(self) -> Optional[bytes]:
        """í˜„ì¬ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return st.session_state.current_image

    def set_analysis_result(self, result: str, raw: Dict) -> None:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"""
        st.session_state.analysis_result = {'text': result, 'raw': raw}

    def get_analysis_result(self) -> Optional[Dict]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return st.session_state.analysis_result

    def set_normalized_result(self, result: Dict[str, Any]) -> None:
        """ì •ê·œí™”ëœ ê²°ê³¼ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤"""
        st.session_state.normalized_result = result

    def get_normalized_result(self) -> Optional[Dict[str, Any]]:
        """ì •ê·œí™”ëœ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        return st.session_state.normalized_result

    def reset(self) -> None:
        """ëª¨ë“  ìƒíƒœë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤"""
        st.session_state.analysis_step = 'image_input'
        st.session_state.current_image = None
        st.session_state.analysis_result = None
        st.session_state.normalized_result = None
        st.session_state.label_saved = False  # ë¼ë²¨ ì €ì¥ ìƒíƒœ ì´ˆê¸°í™”


class ImageUploadStep:
    """Step 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ/ìº¡ì²˜"""

    def __init__(self, app_context):
        self.app_context = app_context

    def render(self, state: AnalysisState) -> Optional[bytes]:
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤"""
        # ì´ë¯¸ì§€ ì…ë ¥ ë°©ì‹ ì„ íƒ (íƒ­)
        tab1, tab2 = st.tabs(["ğŸ“· ì¹´ë©”ë¼", "ğŸ–¼ï¸ íŒŒì¼ ì—…ë¡œë“œ"])

        with tab1:
            st.markdown("**ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ ì´¬ì˜**")
            camera_image = st.camera_input("ì‚¬ì§„ì„ ì´¬ì˜í•˜ì„¸ìš”")
            if camera_image:
                return camera_image.getvalue()

        with tab2:
            st.markdown("**íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì„ íƒ**")
            uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", type=['jpg', 'jpeg', 'png'])
            if uploaded_file:
                return uploaded_file.getvalue()

        return None


class AnalysisStep:
    """Step 2: OpenAI Vision APIë¡œ ì´ë¯¸ì§€ ë¶„ì„"""

    def __init__(self, app_context):
        self.app_context = app_context

    def render(self, state: AnalysisState, model: str, prompt: str) -> bool:
        """ì´ë¯¸ì§€ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤"""
        image_bytes = state.get_image()

        if not image_bytes:
            st.error("ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        st.subheader("ğŸ§  ì´ë¯¸ì§€ ë¶„ì„")

        # ì´ë¯¸ì§€ í‘œì‹œ
        st.image(image_bytes, caption="ë¶„ì„í•  ì´ë¯¸ì§€", use_container_width=True)

        # ë¶„ì„ ì˜µì…˜
        col1, col2 = st.columns(2)

        with col1:
            max_size = st.slider(
                "ìµœëŒ€ ë³€í™˜ í¬ê¸° (px)",
                min_value=480,
                max_value=1280,
                value=1024,
                step=64,
                key="max_size"
            )

        with col2:
            st.metric("í”„ë¡¬í”„íŠ¸ ê¸¸ì´", f"{len(prompt)} ì")

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ í™•ì¸ (expander)
        with st.expander("ğŸ” AIì— ì „ë‹¬ë˜ëŠ” ìµœì¢… í”„ë¡¬í”„íŠ¸ í™•ì¸", expanded=False):
            st.markdown("**AIì— ë‹¤ìŒì˜ í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì´ë¯¸ì§€ê°€ ì „ë‹¬ë©ë‹ˆë‹¤:**")
            st.markdown("---")
            st.code(prompt, language="markdown")
            st.markdown("---")
            st.info("ğŸ’¡ í”„ë¡¬í”„íŠ¸ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ì„±ë˜ì§€ ì•Šì•˜ë‹¤ë©´ AIì˜ ë¶„ë¥˜ ê²°ê³¼ê°€ ë¶€ì •í™•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # ë¶„ì„ ë²„íŠ¼
        if not st.button("ğŸ” ë¶„ì„ ì‹œì‘", use_container_width=True, key="start_analysis"):
            return False

        # OpenAI ì„œë¹„ìŠ¤ í™•ì¸
        openai_service = self.app_context.get_service('openai_service')
        if not openai_service or not openai_service.is_ready():
            st.error("OpenAI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        if not openai_service.has_api_key():
            st.error("OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤")
            return False

        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        try:
            from src.domains.analysis.services.openai_service import jpeg_bytes_from_image

            with st.spinner("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘..."):
                jpeg_bytes = jpeg_bytes_from_image(image_bytes, int(max_size), 85)

            # LLM ë¶„ì„
            with st.spinner("ğŸ¤– AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                output_text, raw = openai_service.analyze_image(jpeg_bytes, prompt.strip(), model)

                if not output_text or not raw:
                    st.error("ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return False

                # ê²°ê³¼ ì €ì¥
                state.set_analysis_result(output_text, raw)
                st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                return True

        except Exception as e:
            error_info = get_error_handler().handle_error(e)
            create_streamlit_error_ui(error_info)
            return False


class ConfirmationStep:
    """Step 3: ë¶„ì„ ê²°ê³¼ í™•ì¸ ë° ë¶„ë¥˜ ì„ íƒ"""

    def __init__(self, app_context):
        self.app_context = app_context

    def _parse_analysis_result(self, output_text: str) -> Dict[str, Any]:
        """LLM ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤"""
        import json

        try:
            # JSON ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ ì¶”ì¶œ
            import re
            json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', output_text)
            if json_match:
                output_text = json_match.group(1).strip()

            parsed = json.loads(output_text)
            return parsed
        except json.JSONDecodeError:
            st.warning("JSON íŒŒì‹± ì‹¤íŒ¨. í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return {
                'object_name': 'ì•Œ ìˆ˜ ì—†ìŒ',
                'primary_category': 'ê¸°íƒ€',
                'secondary_category': 'ë¶„ë¥˜ë¶ˆê°€',
                'confidence': 0.3,
                'reasoning': 'ìë™ íŒŒì‹± ì‹¤íŒ¨'
            }

    def _normalize_result(self, parsed: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤"""
        waste_service = self.app_context.get_service('waste_classification_service')
        ai_mapper = self.app_context.get_service('ai_classification_mapper')

        # ê¸°ë³¸ í•„ë“œ ì¶”ì¶œ
        object_name = parsed.get('object_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
        primary_category = parsed.get('primary_category') or parsed.get('main_category', 'ê¸°íƒ€')
        secondary_category = parsed.get('secondary_category') or parsed.get('sub_category', 'ë¶„ë¥˜ë¶ˆê°€')
        confidence = float(parsed.get('confidence', 0.5))
        dimensions = parsed.get('dimensions', {}) or parsed.get('size_estimation', {})

        normalized = {
            'object_name': object_name,
            'primary_category': primary_category,
            'secondary_category': secondary_category,
            'confidence': confidence,
            'dimensions': dimensions,
            'reasoning': parsed.get('reasoning', ''),
            'raw_response': parsed
        }

        return normalized

    def render(self, state: AnalysisState) -> Optional[Dict[str, Any]]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë¶„ë¥˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤"""
        analysis_result = state.get_analysis_result()

        if not analysis_result:
            st.error("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # ë¶„ì„ëœ ì´ë¯¸ì§€ í‘œì‹œ
        image_bytes = state.get_image()
        if image_bytes:
            st.image(image_bytes, caption="ë¶„ì„ëœ ì´ë¯¸ì§€", use_container_width=True)
            st.markdown("---")

        # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
        parsed = self._parse_analysis_result(analysis_result['text'])
        normalized = self._normalize_result(parsed)

        # ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì½¤ë³´ë°•ìŠ¤ í˜•íƒœ)
        st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")

        # ë¬¼í’ˆëª… í‘œì‹œ
        st.write(f"**ê°ì§€ëœ ë¬¼í’ˆ:** {normalized['object_name']}")

        # íê¸°ë¬¼ ë¶„ë¥˜ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        waste_service = self.app_context.get_service('waste_classification_service')

        # íê¸°ë¬¼ ë¶„ë¥˜ ì„œë¹„ìŠ¤ í™•ì¸
        if not waste_service:
            st.warning("âš ï¸ íê¸°ë¬¼ ë¶„ë¥˜ ì„œë¹„ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ í˜ì´ì§€ì—ì„œ ë¶„ë¥˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

        col1, col2 = st.columns(2)

        # ëŒ€ë¶„ë¥˜ ì„ íƒ
        with col1:
            main_categories = waste_service.get_main_categories() if waste_service else []
            if not main_categories:
                st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€ë¶„ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                selected_main = st.selectbox(
                    "ëŒ€ë¶„ë¥˜",
                    options=main_categories,
                    index=main_categories.index(normalized['primary_category']) if normalized['primary_category'] in main_categories else 0,
                    key="result_main_category",
                    help="íê¸°ë¬¼ì˜ ì£¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                )
                normalized['primary_category'] = selected_main

        # ì„¸ë¶„ë¥˜ ì„ íƒ
        with col2:
            if waste_service and waste_service.get_main_categories():
                # í˜„ì¬ ì„ íƒëœ ëŒ€ë¶„ë¥˜ì˜ ì„¸ë¶„ë¥˜ ê°€ì ¸ì˜¤ê¸°
                current_main = normalized.get('primary_category')
                if current_main:
                    subcategories = waste_service.get_subcategories(current_main)
                    if subcategories:
                        sub_options = [sub.get('ëª…ì¹­', '') for sub in subcategories]

                        # í˜„ì¬ ì„ íƒëœ ì„¸ë¶„ë¥˜ì˜ ì¸ë±ìŠ¤ ê³„ì‚°
                        try:
                            default_index = sub_options.index(normalized['secondary_category'])
                        except (ValueError, IndexError):
                            default_index = 0

                        selected_sub = st.selectbox(
                            "ì„¸ë¶„ë¥˜",
                            options=sub_options,
                            index=default_index,
                            key=f"result_sub_category_{current_main}",  # ëŒ€ë¶„ë¥˜ë³„ ê³ ìœ  í‚¤
                            help="íê¸°ë¬¼ì˜ ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”"
                        )
                        normalized['secondary_category'] = selected_sub
                    else:
                        st.warning(f"âš ï¸ '{current_main}'ì— í•´ë‹¹í•˜ëŠ” ì„¸ë¶„ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        normalized['secondary_category'] = "ë¶„ë¥˜ë¶ˆê°€"
                else:
                    st.info("ğŸ’¡ ë¨¼ì € ëŒ€ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
            else:
                st.write(f"**ì„¸ë¶„ë¥˜:** {normalized.get('secondary_category', 'ë¶„ë¥˜ë¶ˆê°€')}")

        # ì‹ ë¢°ë„ í‘œì‹œ
        st.metric("ì‹ ë¢°ë„", f"{normalized['confidence']:.0%}")

        # ì‹ ë¢°ë„ ì¡°ì •
        st.markdown("---")
        confidence_rating = st.slider(
            "ì‹ ë¢°ë„ ì¡°ì •",
            min_value=1,
            max_value=5,
            value=int(normalized['confidence'] * 5) if normalized['confidence'] > 0 else 3,
            key="confidence_rating"
        )
        normalized['confidence'] = confidence_rating / 5

        # í¬ê¸° ì •ë³´ ì„¹ì…˜
        st.markdown("---")
        st.subheader("ğŸ“ í¬ê¸° ì •ë³´ (3D ì°¨ì›)")

        dimensions = normalized.get('dimensions', {})

        if dimensions and any(dimensions.values()):
            # í¬ê¸° ì •ë³´ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
            col1, col2, col3 = st.columns(3)

            with col1:
                w_val = dimensions.get('w_cm') or dimensions.get('width_cm', '-')
                st.metric("ê°€ë¡œ(W)", f"{w_val} cm", help="ì •ë©´ì—ì„œ ë³¸ ì¢Œìš° ê¸¸ì´")

            with col2:
                h_val = dimensions.get('h_cm') or dimensions.get('height_cm', '-')
                st.metric("ë†’ì´(H)", f"{h_val} cm", help="ì •ë©´ì—ì„œ ë³¸ ìƒí•˜ ê¸¸ì´")

            with col3:
                d_val = dimensions.get('d_cm') or dimensions.get('depth_cm', '-')
                st.metric("ê¹Šì´(D)", f"{d_val} cm", help="ë¬¼ì²´ì˜ ì•ë’¤ ê¸¸ì´(ê¹Šì´)")

            # í¬ê¸° ìˆ˜ì • ì˜µì…˜
            modify_size = st.checkbox("í¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", key="modify_size_info")

            if modify_size:
                st.markdown("**ìŠ¬ë¼ì´ë”ë¡œ í¬ê¸°ë¥¼ ì¡°ì •í•˜ì„¸ìš” (ë‹¨ìœ„: cm):**")

                width = st.slider(
                    "ê°€ë¡œ(W) - ì •ë©´ì—ì„œ ë³¸ ì¢Œìš° ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=int(dimensions.get('w_cm') or dimensions.get('width_cm') or 0),
                    step=5,
                    key="mod_width"
                )

                height = st.slider(
                    "ë†’ì´(H) - ì •ë©´ì—ì„œ ë³¸ ìƒí•˜ ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=int(dimensions.get('h_cm') or dimensions.get('height_cm') or 0),
                    step=5,
                    key="mod_height"
                )

                depth = st.slider(
                    "ê¹Šì´(D) - ë¬¼ì²´ì˜ ì•ë’¤ ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=int(dimensions.get('d_cm') or dimensions.get('depth_cm') or 0),
                    step=5,
                    key="mod_depth"
                )

                normalized['dimensions'] = {
                    'w_cm': width if width > 0 else None,
                    'h_cm': height if height > 0 else None,
                    'd_cm': depth if depth > 0 else None
                }
        else:
            # í¬ê¸° ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
            st.info("ğŸ’¡ í¬ê¸° ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì§ì ‘ ì…ë ¥í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            provide_size = st.checkbox(
                "ì§ì ‘ í¬ê¸°ë¥¼ ì…ë ¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                key="provide_size_manual"
            )

            if provide_size:
                st.markdown("**ìŠ¬ë¼ì´ë”ë¡œ ì‹¤ì œ í¬ê¸°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ë‹¨ìœ„: cm):**")

                width = st.slider(
                    "ê°€ë¡œ(W) - ì •ë©´ì—ì„œ ë³¸ ì¢Œìš° ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=0,
                    step=5,
                    key="manual_width"
                )

                height = st.slider(
                    "ë†’ì´(H) - ì •ë©´ì—ì„œ ë³¸ ìƒí•˜ ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=0,
                    step=5,
                    key="manual_height"
                )

                depth = st.slider(
                    "ê¹Šì´(D) - ë¬¼ì²´ì˜ ì•ë’¤ ê¸¸ì´",
                    min_value=0,
                    max_value=300,
                    value=0,
                    step=5,
                    key="manual_depth"
                )

                if any([width > 0, height > 0, depth > 0]):
                    normalized['dimensions'] = {
                        'w_cm': width if width > 0 else None,
                        'h_cm': height if height > 0 else None,
                        'd_cm': depth if depth > 0 else None
                    }

        # ê¸°íƒ€ ë¶„ë¥˜ì¸ ê²½ìš° ì‚¬ìš©ì ì…ë ¥
        if normalized['primary_category'] == 'ê¸°íƒ€' and normalized['secondary_category'] == 'ë¶„ë¥˜ë¶ˆê°€':
            st.markdown("---")
            user_input = st.text_input(
                "ë¬¼í’ˆ ìƒì„¸ ì„¤ëª…",
                placeholder="ì˜ˆ: ëª©ì¬ ì„ ë°˜, ìŠ¤í…Œì¸ë¦¬ìŠ¤ ì‹íƒ",
                max_chars=100,
                key="user_custom_name"
            )
            normalized['user_custom_name'] = user_input

        # ì‚¬ìš©ì í”¼ë“œë°± ì„¹ì…˜
        st.markdown("---")
        st.subheader("ğŸ’¬ ì¶”ê°€ ì •ë³´")

        feedback_notes = st.text_area(
            "ë¶„ë¥˜ ë˜ëŠ” í¬ê¸°ì— ëŒ€í•´ ì¶”ê°€ë¡œ ì•Œë ¤ì£¼ì‹¤ ë‚´ìš©ì´ ìˆìœ¼ì‹ ê°€ìš”? (ì„ íƒì‚¬í•­)",
            placeholder="ì˜ˆ: ë¶„ë¦¬ê°€ ê°€ëŠ¥í•œ ì œí’ˆì…ë‹ˆë‹¤, íŠ¹ë³„í•œ ì¬ì§ˆë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤ ë“±",
            height=100,
            key="feedback_notes"
        )

        normalized['user_feedback'] = {
            'notes': feedback_notes.strip(),
            'timestamp': datetime.now().isoformat()
        }

        # AI í”¼ë“œë°± ì„¹ì…˜ (ì„ íƒì )
        st.markdown("---")
        st.subheader("ğŸ¤– AI í”¼ë“œë°± (ì„ íƒ)")

        if st.button("ğŸ’­ AI ì˜ê²¬ ë“£ê¸°", use_container_width=True, key="get_ai_feedback"):
            try:
                # í”„ë¡¬í”„íŠ¸ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                prompt_service = self.app_context.get_service('prompt_service')
                openai_service = self.app_context.get_service('openai_service')

                if prompt_service and openai_service:
                    # Simple Prompt íŒ¨í„´:
                    # 1. ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ë˜ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±)
                    confirmation_prompt = prompt_service.get_default_prompt_for_feature('confirmation_analysis')

                    if confirmation_prompt:
                        # 2. ë³€ìˆ˜ ì¤€ë¹„
                        dimensions = normalized.get('dimensions', {})
                        dimensions_str = f"{dimensions.get('w_cm', '-')}cm x {dimensions.get('h_cm', '-')}cm x {dimensions.get('d_cm', '-')}cm"

                        variables = {
                            'item_name': normalized['object_name'],
                            'category': normalized['primary_category'],
                            'dimensions': dimensions_str,
                            'confidence': f"{normalized['confidence']:.0%}",
                            'user_feedback': feedback_notes.strip() or 'ì—†ìŒ'
                        }

                        # 3. í”„ë¡¬í”„íŠ¸ ë Œë”ë§ (ë³€ìˆ˜ ì¹˜í™˜)
                        rendered_prompt = prompt_service.render_prompt(
                            confirmation_prompt.id,
                            variables
                        )

                        if rendered_prompt:
                            # 4. LLM í˜¸ì¶œ
                            with st.spinner("ğŸ¤– AIê°€ í”¼ë“œë°±ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                                feedback_result = openai_service.call_with_prompt(rendered_prompt)

                            if feedback_result:
                                st.success("âœ… AI í”¼ë“œë°±")
                                st.markdown(feedback_result)
                            else:
                                st.warning("AI í”¼ë“œë°± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                        else:
                            st.warning("í”„ë¡¬í”„íŠ¸ ë Œë”ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                    else:
                        st.info("ğŸ’¡ ì €ì¥ëœ í”¼ë“œë°± í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. Adminì—ì„œ 'confirmation_analysis' ê¸°ëŠ¥ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
                else:
                    st.error("í•„ìš”í•œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            except Exception as e:
                error_info = get_error_handler().handle_error(e)
                st.warning(f"AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                logger.error(f"AI feedback generation error: {e}", exc_info=True)

        # ìµœì¢… í™•ì¸ ë²„íŠ¼
        st.markdown("---")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("âœ… í™•ì¸", use_container_width=True, key="confirm_btn"):
                state.set_normalized_result(normalized)
                state.set_step('complete')
                return normalized

        with col2:
            if st.button("ğŸ”™ ë‹¤ì‹œ ë¶„ì„", use_container_width=True, key="retry_btn"):
                state.reset()
                st.rerun()

        return None


class CompleteStep:
    """Step 4: ë¶„ë¥˜ ì™„ë£Œ ë° ë°°ì¶œ ì•ˆë‚´"""

    def __init__(self, app_context):
        self.app_context = app_context

    def render(self, state: AnalysisState) -> None:
        """ë¶„ë¥˜ ì™„ë£Œ í™”ë©´ì„ ë Œë”ë§í•©ë‹ˆë‹¤"""
        normalized = state.get_normalized_result()

        if not normalized:
            st.error("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return

        # ë¶„ì„ëœ ì´ë¯¸ì§€ í‘œì‹œ
        image_bytes = state.get_image()
        if image_bytes:
            st.image(image_bytes, caption="ë¶„ì„ëœ ì´ë¯¸ì§€", use_container_width=True)
            st.markdown("---")

        # ìµœì¢… ê²°ê³¼ í‘œì‹œ
        result_container = st.container(border=True)

        with result_container:
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric("ë¬¼í’ˆëª…", normalized['object_name'])

            with col2:
                st.metric("ëŒ€ë¶„ë¥˜", normalized['primary_category'])

            with col3:
                st.metric("ì„¸ë¶„ë¥˜", normalized['secondary_category'])

        # í”¼ë“œë°± ì €ì¥ ë° ë¼ë²¨ë§ ë°ì´í„° ì €ì¥ (ë‹¨ í•œ ë²ˆë§Œ)
        if not st.session_state.get('label_saved', False):
            try:
                confirmation_service = self.app_context.get_service('confirmation_service')

                if confirmation_service:
                    # í”¼ë“œë°± ë°ì´í„° êµ¬ì„±
                    feedback_data = {
                        "classification": {
                            "object_name": normalized.get('object_name'),
                            "primary_category": normalized.get('primary_category'),
                            "secondary_category": normalized.get('secondary_category'),
                            "confidence": normalized.get('confidence')
                        },
                        "dimensions": normalized.get('dimensions', {}),
                        "user_feedback": normalized.get('user_feedback', {}),
                        "timestamp": datetime.now().isoformat()
                    }

                    # í”¼ë“œë°± ì €ì¥
                    save_result = confirmation_service.save_confirmation(
                        session_id=st.session_state.get('session_id', 'unknown'),
                        image_id=st.session_state.get('image_id', 'unknown'),
                        original_analysis=normalized,
                        is_correct=True,
                        corrected_data={'feedback_details': feedback_data}
                    )

                    if save_result and save_result.get('success'):
                        st.success("âœ… ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.info("ğŸ’¾ í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")

                        # ë¼ë²¨ë§ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥
                        try:
                            labeling_service = self.app_context.get_service('labeling_service')
                            if labeling_service:
                                if image_bytes:
                                    label_result = labeling_service.save_label(
                                        image_bytes=image_bytes,
                                        analysis_result=normalized,
                                        user_feedback=normalized.get('user_feedback', {})
                                    )

                                    if label_result.get('success'):
                                        st.success(f"ğŸ“Š í•™ìŠµ ë°ì´í„°ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {label_result.get('file_id')})")
                                        logger.info(f"Label saved successfully: {label_result.get('file_id')}")

                                        # ë¼ë²¨ ì €ì¥ ì™„ë£Œ í‘œì‹œ
                                        st.session_state.label_saved = True
                                    else:
                                        st.warning(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {label_result.get('error')}")
                                        logger.warning(f"Label save failed: {label_result.get('error')}")
                                else:
                                    logger.warning("ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                            else:
                                logger.warning("LabelingServiceë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        except Exception as e:
                            logger.error(f"ë¼ë²¨ë§ ë°ì´í„° ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
                            st.warning(f"ë¼ë²¨ë§ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

            except Exception as e:
                st.warning(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

        # ë°°ì¶œ ë°©ë²• ì•ˆë‚´ (ì„ íƒì‚¬í•­)
        st.markdown("---")
        st.subheader("ğŸ“– ë°°ì¶œ ë°©ë²• ì•ˆë‚´")

        if st.button("ğŸ’¡ ë°°ì¶œ ë°©ë²• í™•ì¸", use_container_width=True, key="show_disposal"):
            try:
                # í”„ë¡¬í”„íŠ¸ ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                prompt_service = self.app_context.get_service('prompt_service')
                openai_service = self.app_context.get_service('openai_service')
                location_service = self.app_context.get_service('location_service')

                if prompt_service and openai_service:
                    # Simple Prompt íŒ¨í„´:
                    # 1. ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                    disposal_prompt = prompt_service.get_default_prompt_for_feature('disposal_guidance_main')

                    if disposal_prompt:
                        # 2. ë³€ìˆ˜ ì¤€ë¹„
                        dimensions = normalized.get('dimensions', {})
                        dimensions_str = f"{dimensions.get('w_cm', '-')}cm x {dimensions.get('h_cm', '-')}cm x {dimensions.get('d_cm', '-')}cm"

                        # ìœ„ì¹˜ ì •ë³´ (í˜„ì¬ ì„ íƒëœ ìœ„ì¹˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©)
                        location_info = st.session_state.get('selected_location', {}) or {}
                        location_full = location_info.get('full_address', 'ë¯¸ì§€ì •')
                        location_code = location_info.get('code', '')

                        # RAGë¥¼ í†µí•´ ì§€ì—­ë³„ ë°°ì¶œ ì •ë³´ ìˆ˜ì§‘ (ì„ íƒì )
                        location_context = 'ì¼ë°˜ ë°°ì¶œ ê·œì •'
                        if location_service and location_code:
                            try:
                                rag_service = self.app_context.get_service('rag_context_service')
                                if rag_service:
                                    rag_result = rag_service.search_disposal_guidance(
                                        location_code=location_code,
                                        waste_category=normalized['primary_category']
                                    )
                                    if rag_result and rag_result.get('success'):
                                        location_context = rag_result.get('location_context', location_context)
                            except Exception as e:
                                logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                                # RAG ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

                        variables = {
                            'location_full': location_full,
                            'item_name': normalized['object_name'],
                            'category': normalized['primary_category'],
                            'dimensions': dimensions_str,
                            'location_context': location_context,
                            'waste_context': f"ì„¸ë¶„ë¥˜: {normalized['secondary_category']}"
                        }

                        # 3. í”„ë¡¬í”„íŠ¸ ë Œë”ë§ (ë³€ìˆ˜ ì¹˜í™˜)
                        rendered_prompt = prompt_service.render_prompt(
                            disposal_prompt.id,
                            variables
                        )

                        if rendered_prompt:
                            # 4. LLM í˜¸ì¶œ
                            with st.spinner("ğŸ¤– ë°°ì¶œ ë°©ë²•ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                                disposal_result = openai_service.call_with_prompt(rendered_prompt)

                            if disposal_result:
                                st.success("âœ… ë°°ì¶œ ë°©ë²• ì•ˆë‚´")
                                st.markdown(disposal_result)
                            else:
                                st.warning("ë°°ì¶œ ë°©ë²• ì•ˆë‚´ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                        else:
                            st.warning("í”„ë¡¬í”„íŠ¸ ë Œë”ë§ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                    else:
                        st.info("ğŸ’¡ ì €ì¥ëœ ë°°ì¶œ ì•ˆë‚´ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. Adminì—ì„œ 'disposal_guidance_main' ê¸°ëŠ¥ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.\n\n"
                               f"ê¸°ë³¸ ë°°ì¶œ ë°©ë²•:\n"
                               f"1. í•´ë‹¹ ì§€ì—­ì˜ íê¸°ë¬¼ ê´€ë¦¬ ë¶€ì„œ í™•ì¸\n"
                               f"2. **{normalized['object_name']}** ({normalized['primary_category']})ì˜ ë°°ì¶œ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n"
                               f"3. ë°°ì¶œ ì‹ ì²­ ë° ìˆ˜ê±° ì˜ˆì•½")
                else:
                    st.error("í•„ìš”í•œ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            except Exception as e:
                logger.error(f"Disposal guidance generation error: {e}", exc_info=True)
                st.warning(f"ë°°ì¶œ ë°©ë²• ì•ˆë‚´ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

        # ì´ˆê¸°í™” ë²„íŠ¼
        st.markdown("---")

        if st.button("ğŸ”„ ìƒˆë¡œìš´ ì‚¬ì§„ ë¶„ì„", use_container_width=True, key="new_analysis"):
            state.reset()
            st.rerun()


@handle_errors(show_user_message=True, reraise=False)
def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    # í˜ì´ì§€ ì„¤ì •
    st.set_page_config(
        page_title="EcoGuide.v1 - ëŒ€í˜•íê¸°ë¬¼ ë¶„ë¥˜",
        page_icon="ğŸ“·",
        layout="centered"
    )

    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
    try:
        app_context = get_application()
    except Exception as e:
        st.error("ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        create_streamlit_error_ui(get_error_handler().handle_error(e))
        st.stop()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    SessionStateManager.init_image_state()
    SessionStateManager.init_ui_state()
    SessionStateManager.init_location_state()

    state = AnalysisState()

    # íê¸°ë¬¼ ë¶„ë¥˜ ê´€ë¦¬ í˜ì´ì§€ í™•ì¸
    if st.session_state.get('show_waste_management', False):
        from src.domains.analysis.ui.waste_types_management import WasteTypesManagementComponent
        waste_mgmt = WasteTypesManagementComponent(app_context)

        # ë’¤ë¡œ ê°€ê¸° ë²„íŠ¼
        col1, col2 = st.columns([4, 1])
        with col2:
            if st.button("ğŸ”™ ë‹«ê¸°", use_container_width=True, key="close_waste_mgmt"):
                st.session_state.show_waste_management = False
                st.rerun()

        st.markdown("---")
        waste_mgmt.render()
        return  # st.stop() ëŒ€ì‹  return ì‚¬ìš©

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.title("âš™ï¸ ì„¤ì •")
        st.markdown("---")

        # ëª¨ë¸ ì„ íƒ
        model = st.selectbox(
            "ë¶„ì„ ëª¨ë¸",
            options=["gpt-4o-mini", "gpt-4-vision"],
            index=0,
            key="model_select"
        )

        st.markdown("---")

        # ì§„í–‰ ìƒíƒœ í‘œì‹œ
        st.subheader("ì§„í–‰ ìƒíƒœ")
        step_names = {
            'image_input': "1ï¸âƒ£ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            'analysis': "2ï¸âƒ£ ë¶„ì„ ì¤‘",
            'confirmation': "3ï¸âƒ£ ê²°ê³¼ í™•ì¸",
            'complete': "4ï¸âƒ£ ì™„ë£Œ"
        }
        current_step = state.get_step()
        for step_id, step_name in step_names.items():
            if step_id == current_step:
                st.write(f"**{step_name} â† í˜„ì¬**")
            else:
                st.write(step_name)

        st.markdown("---")

        # ê´€ë¦¬ í˜ì´ì§€ ë§í¬
        st.subheader("ğŸ› ï¸ ê´€ë¦¬")

        if st.button("ğŸ—‚ï¸ íê¸°ë¬¼ ë¶„ë¥˜ ê´€ë¦¬", use_container_width=True, key="waste_mgmt_button"):
            st.session_state.show_waste_management = True
            st.rerun()  # ì¦‰ì‹œ rerunìœ¼ë¡œ ìœ„ì˜ ê´€ë¦¬ í˜ì´ì§€ í‘œì‹œ

        st.markdown("---")

    # ë©”ì¸ ì½˜í…ì¸ 
    st.title("âœ¨ EcoGuide.AI")
    st.caption("ë²„ë¦¬ë ¤ëŠ” ê·¸ ìˆœê°„, ì°°ì¹µ! AIê°€ ìµœì ì˜ ë°©ë²•ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤!")
    st.markdown("---")

    # ì§€ì—­ ì„ íƒ (ë©”ì¸ í™”ë©´ì— í‘œì‹œ)
    st.subheader("ğŸ“ ì§€ì—­ ì„ íƒ")
    from src.domains.district.ui.location_selector import LocationSelectorComponent
    location_selector = LocationSelectorComponent(app_context)
    location = location_selector.render()

    if location and location.get('success'):
        location_data = location.get('data', {})
        st.success(f"ğŸ“ ì„ íƒëœ ìœ„ì¹˜: {location_data.get('sido', '')} {location_data.get('sigungu', '')}")

    st.markdown("---")

    # Step 1: ì´ë¯¸ì§€ ì—…ë¡œë“œ
    if state.get_step() == 'image_input':
        st.header("ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        st.markdown("---")

        upload_step = ImageUploadStep(app_context)
        image_bytes = upload_step.render(state)

        if image_bytes:
            state.set_image(image_bytes)
            state.set_step('analysis')
            st.rerun()

    # Step 2: ë¶„ì„
    elif state.get_step() == 'analysis':

        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        st.subheader("ğŸ“ ë¶„ì„ í”„ë¡¬í”„íŠ¸")

        # waste_types.jsonì—ì„œ ë¶„ë¥˜ ì²´ê³„ í…ìŠ¤íŠ¸ ìƒì„±
        def build_waste_classification_text() -> str:
            """waste_types.jsonì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ë¥˜ ì²´ê³„ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
            import json
            import os

            try:
                # waste_types.json ì°¾ê¸°
                possible_paths = [
                    "uploads/waste_types/waste_types.json",
                    "/home/jaeho/projects_linux/ecoguide.v1/uploads/waste_types/waste_types.json",
                    os.path.join(os.getcwd(), "uploads", "waste_types", "waste_types.json")
                ]

                waste_data = None
                for path in possible_paths:
                    if os.path.exists(path):
                        with open(path, 'r', encoding='utf-8') as f:
                            waste_data = json.load(f)
                        break

                if not waste_data:
                    raise FileNotFoundError("waste_types.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                # ë¶„ë¥˜ ì²´ê³„ í…ìŠ¤íŠ¸ ìƒì„±
                classification_text = "## íê¸°ë¬¼ ë¶„ë¥˜ ì²´ê³„\n\n"

                for main_cat, details in waste_data.items():
                    description = details.get('ì„¤ëª…', '')
                    classification_text += f"### {main_cat} - {description}\n"

                    subcategories = details.get('ì„¸ë¶„ë¥˜', [])
                    for sub in subcategories:
                        name = sub.get('ëª…ì¹­', '')
                        examples = sub.get('ì˜ˆì‹œ', [])
                        if examples:
                            example_str = ', '.join(examples)
                            classification_text += f"- **{name}** ({example_str})\n"
                        else:
                            classification_text += f"- **{name}**\n"

                    classification_text += "\n"

                return classification_text

            except Exception as e:
                logger.warning(f"Failed to load waste_types.json: {e}")
                return ""

        # registry.jsonì—ì„œ ë¶„ì„ ì¸í„°í˜ì´ìŠ¤ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        def load_analysis_prompt_from_registry() -> str:
            """prompt_feature_registry.jsonì—ì„œ analysis_interface í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
            import json
            import os

            try:
                # registry.json ì°¾ê¸°
                possible_paths = [
                    "data/prompts/features/prompt_feature_registry.json",
                    "/home/jaeho/projects_linux/ecoguide.v1/data/prompts/features/prompt_feature_registry.json",
                    os.path.join(os.getcwd(), "data", "prompts", "features", "prompt_feature_registry.json")
                ]

                registry_data = None
                loaded_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        with open(path, 'r', encoding='utf-8') as f:
                            registry_data = json.load(f)
                        loaded_path = path
                        logger.info(f"registry.json ë¡œë“œ ì„±ê³µ: {path}")
                        break

                if not registry_data:
                    logger.warning("registry.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    return None

                # analysis_interface ê¸°ëŠ¥ì˜ í”„ë¡¬í”„íŠ¸ ì°¾ê¸°
                for feature in registry_data.get('features', []):
                    if feature.get('feature_id') == 'analysis_interface':
                        prompt = feature.get('default_prompt_template', None)
                        if prompt:
                            logger.info(f"analysis_interface í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì„±ê³µ (ê¸¸ì´: {len(prompt)} ì)")
                        return prompt

                logger.warning("analysis_interface ê¸°ëŠ¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            except Exception as e:
                logger.error(f"registry.json ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
                return None

        # Fallback í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ ì •ì˜
        def _get_fallback_prompt(classification_text: str) -> str:
            """fallback í”„ë¡¬í”„íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
            return f"""ë‹¹ì‹ ì€ ëŒ€í˜•íê¸°ë¬¼ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì˜ ë¶„ë¥˜ ì²´ê³„ë¥¼ ì •í™•íˆ ë”°ë¼ì„œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

{classification_text}

## ë¶„ì„ ì§€ì¹¨

1. ìœ„ì˜ ë¶„ë¥˜ ì²´ê³„ì—ì„œ **ì •í™•í•œ ëŒ€ë¶„ë¥˜(primary_category)**ë¥¼ ì„ íƒí•˜ì„¸ìš”
2. í•´ë‹¹ ëŒ€ë¶„ë¥˜ ì•„ë˜ì˜ **ì •í™•í•œ ì„¸ë¶„ë¥˜(secondary_category)**ë¥¼ ì„ íƒí•˜ì„¸ìš”
3. ì„¸ë¶„ë¥˜ëŠ” ë°˜ë“œì‹œ ìœ„ ëª©ë¡ì— ìˆëŠ” ê²ƒ ì¤‘ì—ì„œë§Œ ì„ íƒí•˜ì„¸ìš”
4. ì´ë¯¸ì§€ì˜ ë¬¼í’ˆì„ ì‹ë³„í•˜ê³  í¬ê¸°ë¥¼ ì¶”ì •í•˜ì„¸ìš”
5. ì‹ ë¢°ë„ë¥¼ 0.0~1.0 ë²”ìœ„ë¡œ ì§€ì •í•˜ì„¸ìš”

## 3D í¬ê¸°(Width, Height, Depth) ì •ì˜
- **width_cm (ê°€ë¡œ)**: ì •ë©´ì—ì„œ ë³¸ ë¬¼ì²´ì˜ ì¢Œìš° ê¸¸ì´
- **height_cm (ë†’ì´)**: ì •ë©´ì—ì„œ ë³¸ ë¬¼ì²´ì˜ ìƒí•˜ ê¸¸ì´
- **depth_cm (ê¹Šì´)**: ë¬¼ì²´ì˜ ì•ë’¤ ê¹Šì´ (ì•ˆìª½ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ì •ë„)

## ì‘ë‹µ í˜•ì‹ (JSONë§Œ ë°˜í™˜, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì—†ìŒ)

```json
{{
  "object_name": "êµ¬ì²´ì ì¸ ë¬¼í’ˆëª…",
  "primary_category": "ëŒ€ë¶„ë¥˜ëª… (ìœ„ ëª©ë¡ì—ì„œ ì„ íƒ)",
  "secondary_category": "ì„¸ë¶„ë¥˜ëª… (ìœ„ ëª©ë¡ì—ì„œ ì„ íƒ)",
  "confidence": 0.0,
  "dimensions": {{
    "width_cm": 0,
    "height_cm": 0,
    "depth_cm": 0
  }},
  "reasoning": "íŒë‹¨ ê·¼ê±°"
}}
```

**ì¤‘ìš”**: secondary_categoryëŠ” ë°˜ë“œì‹œ ìœ„ì˜ ë¶„ë¥˜ ì²´ê³„ ëª©ë¡ì— ìˆëŠ” ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ê¸°ì…í•˜ì„¸ìš”."""

        # ë¶„ë¥˜ ì²´ê³„ í…ìŠ¤íŠ¸ ìƒì„±
        classification_text = build_waste_classification_text()

        # registry.jsonì—ì„œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° ë³€ìˆ˜ ë°”ì¸ë”©
        registry_prompt = load_analysis_prompt_from_registry()

        if registry_prompt:
            # registry í”„ë¡¬í”„íŠ¸ì— {CLASSIFICATION_TEXT} ë³€ìˆ˜ ë°”ì¸ë”©
            try:
                default_prompt = registry_prompt.format(CLASSIFICATION_TEXT=classification_text)
                logger.info("registry í”„ë¡¬í”„íŠ¸ì— ë¶„ë¥˜ ì²´ê³„ ë°”ì¸ë”© ì„±ê³µ")
            except Exception as e:
                logger.error(f"í”„ë¡¬í”„íŠ¸ ë°”ì¸ë”© ì‹¤íŒ¨: {e}")
                # fallbackìœ¼ë¡œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                default_prompt = _get_fallback_prompt(classification_text)
        else:
            # fallback: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            logger.warning("registry í”„ë¡¬í”„íŠ¸ ë¯¸ë¡œë“œ - fallback í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
            default_prompt = _get_fallback_prompt(classification_text)

        prompt = st.text_area(
            "í”„ë¡¬í”„íŠ¸",
            value=default_prompt,
            height=200,
            key="analysis_prompt"
        )

        # ë¶„ì„ ì‹¤í–‰
        analysis_step = AnalysisStep(app_context)
        if analysis_step.render(state, model, prompt):
            state.set_step('confirmation')
            st.rerun()

    # Step 3: í™•ì¸
    elif state.get_step() == 'confirmation':
        st.header("ğŸ“‹ ë¶„ì„ ê²°ê³¼ í™•ì¸")
        st.markdown("---")

        confirmation_step = ConfirmationStep(app_context)
        result = confirmation_step.render(state)

        if result:
            st.rerun()

    # Step 4: ì™„ë£Œ
    elif state.get_step() == 'complete':
        st.header("âœ… ë¶„ë¥˜ ì™„ë£Œ")
        st.markdown("---")

        complete_step = CompleteStep(app_context)
        complete_step.render(state)


if __name__ == "__main__":
    main()
